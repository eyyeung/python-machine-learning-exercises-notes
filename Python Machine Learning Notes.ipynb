{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Machine Learning Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "\n",
    "## McCulloch-Pitts (MCP) neuron\n",
    "* Describe nerve cell as a simple logic gate with binary outputs\n",
    "* Multiple signals get integrated and if the accumulated signal exceeds a threshold, output signal is generated and passed on by the axon\n",
    "\n",
    "## Artificial neurons\n",
    "* for a binary classification task where there are two classes:\n",
    "    * 1 (postiive class)\n",
    "    * -1 (negative class)\n",
    "* we can define a decision function that takes a combination of certain input values (x) and corresponding weight (w)\n",
    "* if the net input of X(i) is greater than a defeined threshold ($\\theta$), then we predict class 1, otherwise predict class -1\n",
    "* to simplify, we set weight-zero as the negative threshold (-$\\theta$) and x-zero to be 1 so that:\n",
    "    * z = w<sub>0</sub>x<sub>0</sub> + w<sub>1</sub>x<sub>1</sub> + .... +w<sub>m</sub>x<sub>m</sub> = W.T * x (dot product)\n",
    "    * prediction = 1 if z>= 0 and -1 otherwise\n",
    "    * weight-zero (w0) = - threshold, is called the bias unit\n",
    "    \n",
    "## Perceptron learning rule\n",
    "1. Initialzie the wieghts to 0 or small random numbers (need to initialize to small random numbers instead of 0 in order for eta to affect both the scale and the direction of the weight vector)\n",
    "2. For each training example x(i), computer the prediciton output y hat, update the weight\n",
    "    * wj := wj + $\\Delta$ wj\n",
    "    * $\\Delta$ w<sub>j</sub> = $\\eta$(y(i) - y hat (i)) x<sub>j</sub><sup>(i)</sup>\n",
    "    * $\\eta$ is learning rate, y(i) is the true class label, y hat (i) is the predicted class label\n",
    "    \n",
    "## One-vs.-all (OvA) method for multi-class classificaiton\n",
    "* also called one-vs.-rest (OvR)\n",
    "* train one classifier per class, where the particular class is treated as the postiive class and all the rest from the other class are the negative.\n",
    "* so if there are 5 class label, would train 5 classifier total\n",
    "* to assign, we would use our n classifiers and assign the class lable with the HIGHEST confidence (highest net input value in the case of perceptron)\n",
    "\n",
    "## Adaptive linear neurons and the convergence of learning\n",
    "* nickname Adaline (ADAptive LInear NEuron)\n",
    "* Adaline was published by Bernard Widrow and Tedd Hoff\n",
    "* Adaline rule (Widrow-Hoff rule) vs. Rosenblatt's perceptron:\n",
    "    * weights are updated based on a linear activation rather than a unit step function\n",
    "    * Adaline, linear activation function $\\Phi$(z) = z so that $\\Phi$(w.T x) = w.T x\n",
    "    * Adaline algorithm compares the true class labels with the linear activatin function's continuous valued output to get the model error and updates the wieghts\n",
    "    * Perceptron directly compares the true class labels to the predicted class labels\n",
    "* objective function  is the cost function J\n",
    "    * sum of squared errors (SSE) between the calcualted outcome and the true class label: J(w) = 1/2 $\\Sigma$ (y(i) - $\\Phi$(z(i))<sup>2</sup>\n",
    "    * continuous linear activaion function allows the cost function to be differentiable\n",
    "    * convex, so can use gradient descent to find the weightst that minimizes our cost\n",
    "    \n",
    "## Objective function\n",
    "* objective function is the function to be optimzied during the learning process\n",
    "* a key ingredietns of supervised machine learning algorithms\n",
    "* often the objective function is the cost function to be minimized\n",
    "\n",
    "## Gradient descent\n",
    "* w := w + $\\Delta$w\n",
    "* $\\Delta$ w = -$\\eta$ $\\nabla$ J(w)\n",
    "* $\\delta$J/$\\delta$w<sub>j</sub> = - $\\Sigma$ (y(i) - $\\Phi$(z(i)) x<sub>j</sub>(i)\n",
    "* $\\Delta$ w = -$\\eta$ $\\delta$J/$\\delta$w<sub>j</sub> = $\\eta$  $\\Sigma$ (y(i) - $\\Phi$(z(i)) x<sub>j</sub>(i)\n",
    "\n",
    "## Standardization\n",
    "* a feature scaling method\n",
    "* gives our data the projecties of a standard normal distribution:\n",
    "    * zero-mean and unit variance\n",
    "    * shifts the mean of each feature so that it centered at zero\n",
    "    * makes each feature have a standard deviation of 1 (unit variance)\n",
    "* helps gradient descent learning to converge more quickly\n",
    "* x'j = (xj - $\\mu$j) / $\\sigma$ j\n",
    "## Stochastic gradient descent (SGD)\n",
    "* batch gradient descent uses the entire trainign dataset to calculate the cost gradient at each step\n",
    "* stochastic gradient descent update the weights incrementally for each training example\n",
    "    * one step of gradient descent uses 1 training sample only\n",
    "    * alot nosier but can escape shallow local minima more readily if we work with nonlinear cost functions later\n",
    "    * important to present training data in a RANDOM order so we want to shuffle the training dataset for each epoch\n",
    "    * instead of a fixed learning rate, an adaptive learning rate that decreases over time is used:\n",
    "        * eg. c1/ [number of iteration] + c2 where c1, c2 are constant\n",
    "    * can be used for online learning\n",
    "* mini-batch learning\n",
    "    * between batch and stochastic, uses a mini-batch at each step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 - Scikit-learn\n",
    "\n",
    "## Selecting the best algorithm\n",
    "* no free lunch theorem:\n",
    "    * no single classifier works best across all possible scenarios\n",
    "    * compare the performance of a handful of different learning algorithms to select the best model for the paritcular problem\n",
    "1. selecting features and collecting labeled training examples\n",
    "2. choosing performance metric\n",
    "3. choosing a classifier and optimization algorithm\n",
    "4. evaluating the performance of the model\n",
    "5. tuning the algorithm\n",
    "\n",
    "## Modeling class probabilities via logistic regression\n",
    "* perceptron rule would never converges if the classes are not perfectly linearly separable\n",
    "* need logistic regression\n",
    "    * probabilistic model for binary classification\n",
    "    * odds : odds in favor of a particular event can be writte as : p / (1-p) where p is the probability of hte positive event - the event we want to predict.\n",
    "    * logit : logarithm of the odds (log-odds): logit(p) = log (p)/ (1-p) where log is natural log\n",
    "    * inverse of logit funciton is the logistic sigmoid function / sigmoid function : $\\phi$(z) = 1 / (1 + e <sup>-z</sup>)\n",
    "    * z = w.T x \n",
    "    * J($\\phi$(z),y;w) = -y log($\\phi$(z)) - (1-y) log (1-$\\phi$(z))\n",
    "\n",
    "## Tackling overfitting via regularization\n",
    "* if the model overfits- has high variance - performs well on training data but does not generalize well to unseen data\n",
    "* if the model underfits - has high bias - not compelx enough to capture the pattern in our training data and also low performacne on unseen data\n",
    "* variance - consistency / variability of the model prediction for classifying a particular example if we retrain model multipel times (eg on different subsets of the trainign dataset) \n",
    "* bias - how far off the predicitons are from the correct values in general if we rebuild the model multiple tiems on different training datasets\n",
    "* L2 regularization / L2 shrinkage / weight decay: $\\lambda$ / 2 ||w||<sup>2</sup> =  $\\lambda$ /2 $\\sum_{j=1}^{m} wj^2$\n",
    "* J(w) = $\\Sigma$ [-y log($\\phi$(z)) - (1-y) log (1-$\\phi$(z)) ] +  $\\lambda$ / 2 ||w||<sup>2</sup>\n",
    "\n",
    "## Maximum margin classification with support vector machines (SVM)\n",
    "* objective is to maximize the margin\n",
    "* margin defined as the distance between the separating hyperplane (decision boundary) and the training examples that are closest to this hyperplane (support vectors)\n",
    "* large margins - lower generalization error, less likely to overfit\n",
    "* looking at the:\n",
    "    * postive hyperplane parallel to the decision boundary: w0 + w.T x<sub>pos</sub> = 1\n",
    "    * negative hyperplane parallel to the decision boundary: w0 + w.T x<sub>neg</sub> = -1\n",
    "    * substracting the two: w.T (x<sub>pos</sub> - x<sub>neg</sub> = 2\n",
    "    * to normalzie by the length of the vector ||w|| = $\\sqrt{\\sum_{j=1}^{m} w_j^2}$\n",
    "    * $\\frac{w.T (x pos - x neg)}{||w||}$ = $\\frac{2}{||w||}$\n",
    "        * left side is the distance between the positive and negative hyperplane - the margin\n",
    "        * want to maximize the right size $\\frac{2}{||w||}$\n",
    "        * in practice, easier to minimize the reciproal $\\frac{||w||}{2}$\n",
    "\n",
    "### Nonlinearly separable case with slack variables\n",
    "* $\\xi$ : soft-margin classification\n",
    "* linear constraints need to be relaxed for nonlinearly separable data to allow the convergence of the optimization in the presence of misclassifications, under appropriate cost penalization\n",
    "* w<sub>0</sub> + w<sup>T</sup> x<sup>(i)</sup> $\\ge$ 1 - $\\xi$<sup>(i)</sup> if y<sup>(i)</sup> = 1\n",
    "* w<sub>0</sub> + w<sup>T</sup> x<sup>(i)</sup> $\\le$ -1 + $\\xi$<sup>(i)</sup> if y<sup>(i)</sup> = -1\n",
    "* $\\frac{1}{2}$ ||w||<sup>2</sup> + C ( $\\Sigma$ $\\xi$<sup>(i)</sup>)\n",
    "\n",
    "## Solving nonlinear problems using a kernel SVM\n",
    "* SVMs can be easily kernelized to solve nonlinear classification problems\n",
    "* kernel methods - create nonlinear combinations of the original features to project them onto a higher - dimensional space via a mapping function $\\phi$ where the data becomes linearly separable.\n",
    "* $\\phi$ (x<sub>1</sub>, x<sub>2</sub>) = (z<sub>1</sub>, z<sub>2</sub>, z<sub>3</sub>) = (x<sub>1</sub>, x<sub>2</sub>, x<sub>1</sub> <sup>2</sup> + x<sub>2</sub> <sup>2</sup>)\n",
    "\n",
    "## Using the kernel trick to find separating hyperplanes in a high-dimensional space\n",
    "* mapping function : $\\phi$  to transform the training data into a higher-dimensional feature space and train a linear SVM model to classify the data in this new feature space\n",
    "    * making new features is computationally expesnive, solution - kernel trick\n",
    "* kernel trick - define a kernel function: $\\kappa$(x(i),x(j)) = $\\phi$(x(i).T)$\\phi$(x(j))\n",
    "    * radial basis function (RBF) / Gaussian kernel:\n",
    "        * one of the most widely used kernels\n",
    "        * $\\kappa$(x(i),x(j)) = exp ( -  $\\frac{||x(i)-x(j)||^2} ){2sigma^2}$ = $\\kappa$(x(i),x(j)) = exp ( - $\\gamma$ ||x(i)-x(j)||<sup>2</sup>) where $\\gamma$ = $\\frac {1}{2sigma^2}$ , a free parameter to be optimzied\n",
    "    * consdier a kernal as a simpilarity function between a pair of examples\n",
    "## Decision tree learning\n",
    "* if we want interpretability, go for decision tree classifiers\n",
    "* breaks down our data by making a decision based on asking a series of quesitons\n",
    "* starts at tree root and split the data on the feature that results in the largest information gain (IG) -- maximizing IG:\n",
    "    * IG(D<sub>p</sub>, f) = I(D<sub>p</sub>) - $\\sum_{j=1}^m \\frac {N_j}{N_p} I(D_p) $ where f is the feature to perform the split, Dp and Dj are the dataset of the parent and jth child node, I is impurity measure, Np is the total number of training exampels in the parent node, Nj is the number of examples in the jth child node\n",
    "        * lower the impurities of the the child node, the larger the information gain since the IG is the difference between the impurity fo the paretn node and the sum of the child node impurities\n",
    "    * to simplify, most libraries use binary decision trees. Each parent is split into TWO child nodes, Dleft and Dright: IG(D<sub>p</sub>, f) = I(D<sub>p</sub>) - $\\frac{N_left}{N_p}$I(D<sub>left</sub>) -  $\\frac{N_right}{N_p}$I(D<sub>right</sub>)\n",
    "    * 3 impurity measures / splitting criteria commonly used:\n",
    "        * Gini impurity (I<sub>G</sub>)\n",
    "        * entropy (I<sub>H</sub>)\n",
    "        * classification error (I<sub>E</sub>)\n",
    "        \n",
    "### entropy for all non-empty classes (p(i|t) $\\ne$ 0)\n",
    "* I<sub>H</sub>(t) = - $\\sum_i^c p(i|t) log_2 p(i|t) $\n",
    "    * p(i|t) is the proportion of exampels that belong to class i for a particular node t\n",
    "    * entropy 0 if all exampels at a node belong to the same class\n",
    "    * entropy is maximal (1) if we have a uniform class distribution\n",
    "    * entropy criterion attempts to maximize the MUTUAL information in the tree\n",
    "### the Gini impurity\n",
    "* I<sub>G</sub>(t) = - $\\sum_i^c p(i|t) (1-p(i|t)) $ = 1-  $\\sum_i^c p(i|t)^2 $ \n",
    "* maximal if the classes are perfectly mixed\n",
    "* entropy and Gini impurity gives very similar resutls\n",
    "### classificaiton error\n",
    "* I<sub>E</sub>(t) = 1- max{p(i|t)}\n",
    "* useful criteron for prunning but not for growing a deicsion tree\n",
    "## Random forests\n",
    "* known for its good scalability and east of use\n",
    "* a ensemble of decision trees\n",
    "* average multiple deep decision trees that individually suffer from high variance to build a more robust and generalizable model\n",
    "1. draw a random boostrap sample of size n (randomly choose n examples from training set with replacement)\n",
    "2. grow a decision tree from the boostrap sample, at each node:\n",
    "2a. randomly select d features without replacement\n",
    "2b. split the node using the feature that provides the best split according to the objective function (such as by maximzing information gain)\n",
    "3. repeat step 1-2 k times (number of trees)\n",
    "4. aggregate prediciton by each tree to assign the class label by MAJORITY VOTE\n",
    "* don't need to prune the random forest since the ensemble model is robust to nosei from inidividual decision trees, don't need to worry too much about picking hyperparameters\n",
    "* In most implementations, size of bootstrap sample is chosen to be equal to the number of training examples in the original training dataset\n",
    "    * good bias-variance tradeoff\n",
    "* number of featuers (d) at each split should be smaller than the total number of features in the training dataset\n",
    "    * default in scikit-learn is d = $\\sqrt{m}$ where m is the number of features in the training dataset\n",
    "## K-nearest neighbors (KNN) classifier\n",
    "* typical example of a lazy learner\n",
    "    * doesn't learn a discriminative function from the training data but memorizes the training dataset instead\n",
    "    * no cost during the learning process\n",
    "* instance-based learning - memorizing the training dataset\n",
    "1. choose number of k and a distance metric\n",
    "2. find k-nearest neighbors of the data record we want to classify\n",
    "3. assign the class by majority vote\n",
    "* right choice of k is critical\n",
    "* distance metric : Euclidean distance often used, but make sure to standardize the data so each feature contirvutes equally to the distance\n",
    "* very susceptible to overfitting by curse of dimensionality\n",
    "    * feature space becomes increasing sparse for an increasing number of dimensions of a fixed-size training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4\n",
    "\n",
    "## Missing data\n",
    "* before processing, need to pre-process the data to get rid of missing data\n",
    "1. eliminating training examples or features with missing values\n",
    "    * might lose too much valuable data\n",
    "2. inputting missing values\n",
    "    * mean imputation - simple replace missing value with the mean / median / most frequent\n",
    "\n",
    "## Categorical data\n",
    "* ordinal - categorical values that can be sorted or ordered (XL > L > M > S > XS)\n",
    "* nominal - don't imply any order (eg. color)\n",
    "* definie mapping of ordinal data manually , XL > L > M so XL:3, L:2, M: 1\n",
    "* but if we convert nominal data this way, problem is the model will assume they do (red = 2, green = 1, blue =0 would imply red>green>blue)\n",
    "* solution is one-hot encoding:\n",
    "    * create new dummy feature for each unique value in the nominal feature, color would be turned into three new feaures: blue, green, and red and binary (1 or 0) used to indicate the paritcular color\n",
    "\n",
    "## Partitioning dataset into training and testing datasets\n",
    "* 60/40, 70/30, 80/20 depending on size of initial dataset. But if very large, 100,000 might only take 10,000 for testing\n",
    "\n",
    "## Feature scaling\n",
    "* feature scaling important for gradient descent optimization\n",
    "* normalizaiton: rescaling of features to a range of [0,1], a special scale of min-max scaling:\n",
    "    * x norm(i) = (x(i) - x min) / (x max - x min)\n",
    "* standardization: center the feature columns at mean 0 with standard deviaiton of 1 so the feature have the same parameters as a standard normal distribution, makes it easier to learn the weights\n",
    "    * x std (i) = ( x(i) - sample mean of x ) / std deviation of x\n",
    "\n",
    "## Selecting meaningful features\n",
    "* if overfititng / high vairance / doing much better in training than testing then, want to reduce overfitting by:\n",
    "    * collecting more data\n",
    "    * regularization\n",
    "    * choose simpler model with fewer parameters\n",
    "    * reduce dimensionality of the data\n",
    "\n",
    "### L1 and L2 regularization\n",
    "* reduce the complexity of model by penalizaing large individual weights\n",
    "* L2 - squared norm of our weight vector w: ||w||<sub>2</sub><sup>2</sup> = $\\sum_j^m w_j^2$\n",
    "* L1 - sum of absolute values of the weights: ||w||<sub>1</sub> = $\\sum_j^m |w_j|$\n",
    "    * yields sparse feature vectors and most feature weights will be zero, sparisty good fo reducing complexity of high-dimensional dataset with many irrelevant features\n",
    "    * since contours of a L1 regularized system are sharp, more likely that the optimum - intersection between the ellipses of cost function and boundary of L1 diamond is on the axes, which encourages sparsity\n",
    "    \n",
    "## Sequential feature selection algorithms\n",
    "* dimensionality reduction reduce complexity of model\n",
    "    * feature selection - select a subset of original features\n",
    "    * feature extraction - derive info from the feature set to construct new feature subspace\n",
    "* sequential feature selection algorithms - family of greedy search algorithms to reduce initial d- dimensional feature to k-dimensional feature subspace where k < d\n",
    "    * sequential backward selection (SBS) - reduce dimensionary of initial feature subsapce with a minimum decay in the perforamcne of the classifier to imrpvoe upon computational efficiency\n",
    "        * greedy - make locally optimal choices at each stage of combinatorial search probelem, yield a suboptimal soln to the problem\n",
    "            * contrast to exhaustive search, evaluate all pos and find the optimal solution\n",
    "        * SBS sequetnially removes features until new feature subspace contains the desired number of features\n",
    "        * criterion function J that we want to minimize\n",
    "        1. initialize the algorithm with k = d (where d is dimensionality of the full feature space\n",
    "        2. determine the feature x<sup>-</sup> that minimizes the criterion argmax/ (X<sub>k</sub> - x)\n",
    "        3. remove the feature x<sup>-</sup> from the feature set\n",
    "        4. terminate if k equals the number of desired features, otherwise go to step 2\n",
    "## Assessing feature importance with random forests\n",
    "* using random forest, can measure the feature importance as the averaged impurity decresase computed from all deciison trees in the forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 : Dimensionality Reduction\n",
    "\n",
    "## feature extraction\n",
    "* feature extraction transform or project the data into a new feature space\n",
    "* Principal component analysis (PCA) - for unsupervised data compression\n",
    "* Linear discriminant analysis (LDA) - for supervised dimensionality reduction technique for maximizng class separability\n",
    "* Kernel principle component analysis (KPCA) - for nonlinear dimensionality reduction\n",
    "\n",
    "## PCA\n",
    "* construct a d x k -dimensional transformation matrix W that allos us to map a vector x (the features of a training exampel) onto a new k-dimensional subspace with fewere dimension than the original d-dimensional feature space\n",
    "    * xW = z\n",
    "1. standardize the d-dimensional dataset\n",
    "2. construct the covariance matrix - pariwise covariances between the different features\n",
    "    * $\\sigma_{jk} = \\frac{1}{n-1} \\sum_{i=1}^n x_j^i - \\mu_j) (x_k^i - \\mu_k) $ where j and k are two features\n",
    "    * $\\Sigma$ v = $\\lambda$ v where $\\Sigma$ is the covariance matrix\n",
    "3. decompose the covariance matrix into its eigenvectors and eigenvalues\n",
    "4. sort the eigenvalues by decreasing order to rank\n",
    "    * plot the variance explained ratio = $\\frac {\\lambda_j}{\\Sigma_{j=1}^d\\lambda_j}$\n",
    "5. select k eigenvectors with the k largest eigenvalues\n",
    "6. construct a projection matrix W from the top k eigenvectors\n",
    "7. transform the d-dimensinal input dataset X using W to the new k-dimensional space\n",
    "\n",
    "## LDA\n",
    "* assume the data is normally distributed\n",
    "* assume the classes have identical covariance matrices\n",
    "* assume the training exampels are statistically independent of each other\n",
    "* can work resonably well even if these assumptions are not true\n",
    "1. standardize the d-dimensional dataset ( d = # of features)\n",
    "2. for each class, compute the d-dimensional mean vector \n",
    "3. construct the between-class scatter matrix S<sub>B</sub> and the within-class scatter matrix S<sub>w</sub>\n",
    "    * $S_w = \\sum_{i=1}^c S_i $ where the inidividual scatter matrix $S_i = \\sum_{x\\in D_i} (x-m_i) (x-m_i)^T $\n",
    "    * but if each class has different distribution, want to normalize, turns out the covariance matrix $\\Sigma_i$ is a normalized version of the scatter matrix : $\\Sigma_i = \\frac{1}{n_i}S_i $\n",
    "4. computer the eigenvectors and corresponding eigenvalues of the matrix $S_w^{-1} S_B $\n",
    "5. Sort the eigenvalues by decreasing order to rank the correspodning eigenvectors\n",
    "6. choose the k eigenvectors with the k largests eigenvalues to make d x k - dimensional transformation matrix W\n",
    "7. project the examples onto the new feature subspace using W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 - model evaluation and hyperparameter tuning\n",
    "\n",
    "## holdout cross-validation\n",
    "* split our initial dataset into separate training, test and a validaiton dataset\n",
    "    * training used to fit the different modesl\n",
    "    * performance on the validaiton dataset set is used for model selection\n",
    "    * after picking the model and tuning hyperparameters, use the test set to evaluate final performance\n",
    "\n",
    "## k-fold cross-validation\n",
    "* randomly split the training dataset into k folds without replacement, k-1 folds are used for model training and one fold used for performance evaluation. Procedure is repeated k times so we get k models and performance estimates\n",
    "* then calculate the average performacne of the models based on the different, independnet test folds to obtain a overall performance estimate\n",
    "* after finding satisfactory hyperparamters values, retrain the model on the complete training dataset and obtain final performance estimate using the independent test dataset\n",
    "* good standard value for k in k-fold cross-validaiton is 10\n",
    "* stratified cross-validaiton : class label proportiosn are preserved in each fold to ensure each fold is representative of class proporitons in the training dataset\n",
    "\n",
    "## Learning cruves\n",
    "* plotting the number of training samples vs accuracy\n",
    "* high bias - low training and cross-validation accuracy, underfitting\n",
    "    * increase the number of paramters of the model, by collecting or constructing additonal features\n",
    "    * decreasing the degree of regularization\n",
    "* high variance - high training accuracy but low vaidation accuracy / large gap between trainign and cross-validation accuracy\n",
    "    * collect mroe data, reduce the complexity of the model or increase regularization paratmer\n",
    "    * for unregularized model, help to decrease the number of features via feature selection or feature extraction\n",
    "\n",
    "## Validation curves\n",
    "* vary the model paramters vs accuracy\n",
    "\n",
    "## Grid search\n",
    "* brute-force exhaustive search paradigm where we specify a list of values for different hyperparameters then the computer evaluates the model performance for each combo to get the best combo\n",
    "* alternative apporach : randomized search\n",
    "    * much more cost- and time-effective.\n",
    "    \n",
    "## Nested cross-validation\n",
    "* if we want to select among different machine learning algorithms, want to use nested cross-validation\n",
    "* outer k-fold cross-validation loop to split the data into training and test folds, and a inner loop to select the model using k-fold cross-validation on the training fold\n",
    "* after model selection, test fold is used to evalaute model performance\n",
    "\n",
    "## Performance evaluaiton metrics\n",
    "* confusion matrix : square matrix that reports true positive(TP), true negative (TN), false positive (FP) and false negative (FN)\n",
    "* both prediction erorr (ERR) and accuracy (ACC) provide general info about how many examples are misclassified\n",
    "    * ERR = (FP+FN)/ (FP+FN+TP+TN)\n",
    "    * ACC = (TP+TN)/ (FP+FN+TP+TN) = 1-ERR\n",
    "    * true positive rate (TPR) = FP/ P = TP/ (FN+TP)\n",
    "    * false positive rate (FPR) = FP/N = FP/(FP+TN)\n",
    "    * precision (PRE) = TP/ (TP+FP)\n",
    "    * recall (REC) = TPR = TP/ P = TP/ (FN+TP)\n",
    "    * F1 = 2 (PER x REC) / (PRE + REC)\n",
    "* precisiion and recall trade off\n",
    "\n",
    "## Receiver operating characteristic (ROC) graph\n",
    "* ROC grpahs used tool to select models for classificsaiton based on their performance with respect to FPR and TPR, which are computed by shifting the decision threshold of the classfier\n",
    "* the diagonal random guessing, and classificaiton model that fall below the diagonal are worse than random guessing\n",
    "* perfect classifier woudl be top-left corner with TPR of 1 and FPR of 0\n",
    "* computer ROC area under the curve (ROC AUC) to characterize perofrmance of a classificaiton model\n",
    "* also has precision-recall curves for different probability thresholds of a classifier\n",
    "\n",
    "## Scoring metrics for multi-class classification\n",
    "* all scoring metrics before are specific to binary, now talking about scoring metrics specific to multiclass problem via one-vs.-all (OvA) classificaiton\n",
    "* micro-average is calculated from the individual TPs,TNs,FPs, and FNs: PRE<sub>micro</sub> = $\\frac {TP_1 + ... + TP_k}{TP_1 + ... TP_k + FP_1 + ... + FP_k}$\n",
    "    * weigth each instance or prediciton equally\n",
    "* macro-average - average scores of the different systems: PRE<sub>macro</sub> = $\\frac {PRE_1 + ... + PRE_k} { k}$\n",
    "    * weights all classes equally\n",
    "* weighted macro-average is calculated by weighting the score of each class label by the number of true instances when calculating the average\n",
    "    * useful when we have class imbalances\n",
    "\n",
    "## Class imbalance\n",
    "* not only affect evaluaiton, but also fitting\n",
    "* want to assign larger penalty to wrong predictions on the minority class\n",
    "* upsampling the minority class and downsampling the majority class\n",
    "* generating synthetic training sample, one of the most widely used algorithm: Synthetic Minority Over-sampling Technique (SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7 : Ensemble Learning\n",
    "\n",
    "## Ensemble methods\n",
    "* goal is to combine different classifiers into a meta-classifier that has better generalization performance than individual classifier alone\n",
    "* majority voting principle: we select the class label that has been predicted by the majority of classifiers >50% of the vote - strickly speaking, only refers to binary class\n",
    "* plurality voting - select the class label that received the most votes (the mode)\n",
    "* ensemble methods work better than individual classifiers alone:\n",
    "    * assume that all n-base classifiers for a binary classificaiton task have an equal error rate $\\epsilon$. Also assume they are independent and error rates are not correlated\n",
    "    * then error probabilty of an ensemble of base classifiers: P (y$\\ge$ k) = $\\sum_k^n <_k^n> \\epsilon^k (1- \\epsilon)^{n-k} = \\epsilon_{ensemble}$ where $<_n^k>$ is the binomial coefficient n choose k - the number of ways we can choose subsets of k-unoredered elements from a set of size n : $\\frac {n!}{ (n-k)! k!}$\n",
    "    \n",
    "## Majority vote\n",
    "* weighted majority vote $\\hat{y} arg max_i \\sum_{j=1}^m w_j \\chi_A (C_j(x) = i ) $ where $w_j$ is weight assocaited with a base classifier $C_j$ A is the set of unique class labels and $\\chi_A$ is the characteristic function or indicator fucntion, returns 1 if the predcited class of the jth calssifiers matchs i ($C_j $(x) = i), 0 otherwise\n",
    "\n",
    "## Bagging\n",
    "* draw bootstrap samples (random samples with replacement) from the initial training dataset, also known as bootstrap aggregating\n",
    "* each classifier receives a random subset of exampels from the dataset\n",
    "* effective in reducing the variance of a model but ineffectively to reduce model bias\n",
    "\n",
    "## Adaptive boosting (AdaBoost)\n",
    "* the ensemble consists of very simple base classifiers (weak learners), which often only have a slight perforamnce advantage over random guessing\n",
    "* key idea is to focus on training examples that are hard to classify, let the weak learners subsequently learn from misclassified training examples to improve the performance of the ensemble\n",
    "* uses random subsets of training examples drawn from training dataset WITHOUT replacement\n",
    "1. draw random subset of training examples d1 without replacement from training dataset D, to train a weak learner C1\n",
    "2. draw a second random training subset d2 without replacement from D and add 50% of examples that were previously misclassfiied to train a weak learner C2\n",
    "3. find the training example d3 in D which C1 and C2 disagree upon to train a third weak learner C3\n",
    "4. combing C1, C2, and C3 via majority voting\n",
    "* learn the mistakes of the other learners\n",
    "\n",
    "### Gradient boosting\n",
    "* AdaBoost and gradient boosting both boost weak learners to strong learners. But gradient boost update the weights differently and differs in how the weak classifiers are combined\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 8 : Sentiment Analysis\n",
    "\n",
    "## Sentiment analysis\n",
    "* subfield of natural language processing (NLP)\n",
    "* sometimes called opinion mining\n",
    "* first preprocess the data - read them into a panda dataframe\n",
    "\n",
    "### bag-of-words model\n",
    "* represent text as numerical feature vectors\n",
    "* create a vocabulary of unique tokens from the entire set of documents\n",
    "* construct a feature vector from each document that contains count of how often each word occurs in the particular document\n",
    "* since the unique words in each doc represent only a small subset of all the words in the bag-of-words vocab, the feature vectors will mostly consit of zeros -- sparse\n",
    "* raw term frequencies : tf(t,d) - the number of times a term t occurs in a document d\n",
    "* 1-gram or unigram model- each item or token in the vocabulary represnts a single word\n",
    "* n-grams - the contiguous sequences of items in NLP, n could be 1- single word, 2, two words, or more\n",
    "\n",
    "### term frequency-inverse document frequency (tf-idf)\n",
    "* tf-idf(t,d) = tf(t,d) x idf(t,d)\n",
    "* idf(t,d) = $log \\frac {n_d} {1+df(d,t)}$ where $n_d$ is the total number of documents, df(d,t) is the number of documents d containing the term t\n",
    "    * adding the constant 1 to the denominator for the sole purpose of assigning a non-zero value to terms that occur in none of the training exmaples ( so that the denominator would never be 0)\n",
    "    * log is to ensure the low document frequencies are not given too much weight\n",
    "* illustration of its purpose: the word 'is' happen very frequently in document 2, but since it occurs very frequently in document 1 and 3 as well, not likely to be important\n",
    "\n",
    "### cleaning text data\n",
    "* important to remove punctuation, html tag, etc from the text.\n",
    "* substitute via regex (regular expression)\n",
    "\n",
    "### processing documents into tokens\n",
    "* one way to split text (tokenize documents) is to split them into individual words by splitting the cleaned documents at their whitespace characters\n",
    "* another way is word stemming : process of transforming a word into its root form - allows us to map related words to the same stem\n",
    "    * Porter stemmer algorithm - developed by Martin F. Porter in 1979\n",
    "    * others : Snowball stemmer, Lancaster stemmer\n",
    "* stop-word removal - words that are extremly common in all sorts of text and rpobably bear no useful info, e.g.: is, and, has,  etc\n",
    "* if too computationally expensive to process all the data at once, then use out-of-core learning: fitting the classifier incrementally on smaller batches of a dataset\n",
    "\n",
    "## topic modeling with latent dirichlet allocation (LDA)\n",
    "* assigning topics to unlabeled text documents\n",
    "* latent dirichlet allocation (LDA) , not to be confused with linear discriminant analysis\n",
    "* generative probabilistic model that tries to find groups of words that appear frequently together across different documents\n",
    "    * the frequently appearing words represent our topics, assuming each document is a mixture of different words\n",
    "    * input is the bag-of-words model\n",
    "* give na bag-of-words model, LDA decomposes it into two new matrices:\n",
    "    * a document-to-topic matrix\n",
    "    * a word-to-topic matrix\n",
    "* if we multiple the two matrix togetehr, would reproduce the input (the bag-of-words matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9 : Web application\n",
    "\n",
    "## Model persistence\n",
    "* want to have an online model, don't want to retrain model everytime, can use Python's in-built pickle module: serialize and deserialzie Python object structures to compact bytecode\n",
    "    * can save our classifier and reload\n",
    "    * can be a potential security risk\n",
    "\n",
    "## SQLite database for data storage\n",
    "* SQLite database - a single, self-contianed database file that allows us to direclty access storage files\n",
    "* doesn't require a separate server to operator\n",
    "* good for smaller projects and simple web applications\n",
    "* for python, sqlite3\n",
    "\n",
    "## Developing web application with Flask\n",
    "* Flask microframework - core is kept lean and simple but can be easily extended with other libraries\n",
    "* allows us to run our applications locally, great for developing and testing web applicaitons before deploying\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 10 : Regression Analysis\n",
    "* used to predict target variables on a continuous scale\n",
    "\n",
    "## linear regression analysis\n",
    "* simple linear regression / univariate linear regression:\n",
    "    * model the relationship between a single feature (explanatory variable), x, and a continuous-valued target (response variable), y.\n",
    "    * $ y = w_0 + w_1 x$ where $w_0 $ is the y -intercept and $w_1$ is the weight coefficient of the explanatory variable\n",
    "    * best- fitting line called the regression line\n",
    "    * vertical lines from the regression line to the training examples are the offsets / residuals - the errors of our prediction\n",
    "* multiple linear regression:\n",
    "    * $ y = w_0 x_0 + w_1 x_1 + ... + w_m x_m = \\sum_{i=0}^n w_i x_i = w^T x $,where  $w_0$ is the y-intercept with $x_0 = 1$\n",
    "\n",
    "## Visualizing the important characteristics of a dataset\n",
    "* Exploratory data analysis (EDA) - important first step prior to training a machine learning model\n",
    "* scatterplot matrix - allows us to visualize the pair-wise correlations between the different features in this dataset in one place\n",
    "* correlation matrix : quantify and summarize linear relationships between variables\n",
    "    * similar to covariance matrix, can be viewed as a rescaled version \n",
    "    * square matrix that contains the Pearson product-moment correlation coefficient (Pearson's r): measures the linear dependence between pairs of features, ranges from -1 to 1\n",
    "        * postive correlation if r=1, no correlation if r=0, and perfect negative correlation if r=-1\n",
    "        * $ r = \\frac {\\sigma_{xy}} {\\sigma_x \\sigma_y}$ \n",
    "        * $ \\sigma_{xy}$ is the covariance between the features x and y, and $\\sigma_x$ and $\\sigma_y$ are the features' standard deviations\n",
    "    * covariance between a pair of STANDARDIZED features is equal to their linear correlation coefficient\n",
    "\n",
    "## Ordinary least squares linear regression model\n",
    "* OLS method (sometimes also called linear least squares) - minimize the sum of squared vertical distance (residuals or errors) to the training examples\n",
    "* Adaline without the unit step function so we obtain continous target values instead of the class label -1 and 1, and then optimize (minimize) the cost function with other algorithms such as gradient descent\n",
    "* cost function is sum of squared errors (SSE) : $J(w) = \\frac{1}{2} \\sum_{i=1}^n (y^{(i)} - \\hat{y}^{(i)})^2$\n",
    "* analytical solutions of linear regression: the normal equation: $ w = (X^T X)^{-1} X^Ty$\n",
    "\n",
    "##  RANSAC\n",
    "* RANdom SAmple Consensus (RANSAC) - fits a regression model to a subset of the data, the inliers\n",
    "* linear regression can be heavily impacted by the presence of outliers\n",
    "1. select a random number of examples to be inliers and fit the model\n",
    "2. test all other data points against the fitted model and add these points that fall within a user-given tolerance to the inliers\n",
    "3. refit the model using all inliers\n",
    "4. estimate the error of the fitted model versus the inliers\n",
    "5. terminate the algorithm if the perforamcne meets a certain user-defined threshold or a fixed number of iterations\n",
    "* by default scikit-learn uses the Median Absolute Deviaiton (MAD) estimate to select the inlier threshold\n",
    "\n",
    "## Evaluating performance\n",
    "* make train-test split\n",
    "* look at residual plots - can detect nonlinearity and outliers and check if errors are randomly distributed\n",
    "    * errors should be randomly distributed and the residuals to be randomly scattered aroudn the centerline\n",
    "    * if there is patterns, means that our model is unable to capture some explanatory info\n",
    "* mean squared error (MSE) - aberaged value of SSE cost that we minimized to fit the linear regression model\n",
    "    * useful for comparing different regression models or for tuning their paratmers via grid serach and cross-vlaidaiton\n",
    "    * normalizes the SSE by the sample size: MSE = $\\frac {1}{n} \\sum_{i=1}^n (y^{(i)} - \\hat{y}^{(i)})^2$\n",
    "    * not bound, depends on the dataset and feature scaling\n",
    "* coefficient of determination ($R^2$) - standardized version:\n",
    "    * $R^2 = 1 - \\frac{SSE} {SST}$ = 1- $\\frac {MSE}{Var(y)}$\n",
    "    * SST = $\\sum_{i=1}^n (y^{(i)} - \\mu_y )^2$ - variance of the response\n",
    "    \n",
    "## Regularized methods for regression\n",
    "* Ridge regression - L2 penalized model where we simply add the squared sum of the weights to our least-squared cost function:\n",
    "    * J(w)Ridge = $\\sum_{1}^n (y^{(i)} -\\hat{y}^{(i)})^2 + \\lambda ||w||_2^2$ where L2: $\\lambda ||w||_2^2 = lambda \\sum_{j=1}^m w_j^2$\n",
    "    * $w_0$ not regularized\n",
    "* least absolute shrinkage and selection operator (LASSO)\n",
    "    * J(w) LASSO = $\\sum_{i=1}^n (y^{(i)}-\\hat{y}^{(i)})^2)+lambda||w||_1$ where L1: $\\lambda ||w||_1 = lambda \\sum_{j=1}^m |w_j|$\n",
    "    * sum of the absolute magnitudes of the model weights\n",
    "    * select at most n features if m>n where n is the number of training examples\n",
    "    * avoid saturated models\n",
    "* elastic Net\n",
    "    * J(w)ElasticNet = $\\sum_{i=1}^n (y^{(i)}-\\hat{y}^{(i)})^2 + \\lambda_1 \\sum_{j=1}^m w_j^2 + \\lambda_2 \\sum_{j=1}^m |w_j|$\n",
    "    * comprimise between LASSO and ElasticNet, has L1 penalty to genreate sparsity and l2 to select more than n features if m>n\n",
    "    \n",
    "## Polynomial regression\n",
    "* use polynomial regression by adding polynomial terms : $ y= w_0 + w_1x + w_2x^2 +... + w_dx^d$\n",
    "\n",
    "## Log-transform\n",
    "* relationship looks like exponential function : f(x) = $e^{-x}$ then want to do log transformation\n",
    "\n",
    "## Random Forests\n",
    "* ensemble of multiple decision trees\n",
    "* sum of piecewise linear functions\n",
    "* subdivide the input space into smaller regions that become more manageable\n",
    "* less sensitive to outliers\n",
    "\n",
    "### decision tress\n",
    "* does not require any transformation of the data\n",
    "* maximizes the information gain (IG) : $IG(D_p,x_i) = I(D_p) - \\frac{N_{left}}{N_p} I(D_{left}) - \\frac{N_{right}}{N_p}I(D_{right})$ where $x_i$ is the feature to perfrom the split, $N_p$ is the number of training examples in the parent node, I is the impurity function, $D_p$ subest of training examples in the parent node\n",
    "* want to find the feature split that reduces the impurities in the child nodes most\n",
    "* to use a decision tree for regression, we need one for continous variable, so we define the impurity measure of a node t as the MSE: I(t) = MSE(t) = $\\frac{1}{N_t} \\sum_{i \\in D_t} (y^{(i)}-\\hat{y}_t)^2$\n",
    "    * where $N_t$ is the number of traiing examples at node t, $D_t$ is the training subset at node t, $y^{(i)}$ the true target value and $\\hat{y}_t$ the predcited target value(sample mean)\n",
    "    * $\\hat{y}_t = \\frac{1}{N_t} \\sum_{i\\in D_t} y^{(i)}$\n",
    "    * MSE often referred to as within-node variance\n",
    "    * splitting criteron called variance reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 11: Clustering\n",
    "* want to find a natural grouping in data so that items in the same cluseter are more similar to each other than those from a different clusters\n",
    "* most popular: k-means clustering\n",
    "\n",
    "### K-means clustering\n",
    "* belongs to prototype-based clustering\n",
    "    * each cluster is represetned by a prototype, which is either:\n",
    "        * the centroid (average) of similar points with continuous featueres\n",
    "        * or the medoid (the most representative or the point that minimize the distance to all other points that belong to a particular cluster in case of categorical features\n",
    "* one of the drawbacks is we need to specify the number of clusters, k, before hand\n",
    "1. randomly pick k centroids from the exampels as initial cluster centers\n",
    "2. assign each example to the nearest centorid $\\mu^{j},j\\in (1,...,k)$\n",
    "3. move the centorids to the center of the examples that were assigned to it\n",
    "4. repeat until cluster assignments do not change or a user-defiend tolearnce or max num of iteraactions is reached\n",
    "* to measure similarity between objects: squared Euclidean distance between two points x and y in m-dimensional space: $d(x,y)^2 = \\sum_{j=1}^m (x_j-y_j)^2 = ||x-y||_2^2$\n",
    "* want to ddesceibe k-means algorthm as a simple optimizaiton problem, minimze the within-cluster sum of squared erros, also called the cluster inertia:\n",
    "    * SSE = $\\sum_{i=1}^n \\sum_{j=1}^k w^{(i,j)} ||x^{(i)} - \\mu^{(j)}||_2^2$\n",
    "        * $\\mu^{(j)}$ is the centroid for cluster j\n",
    "        * $w^(i,j) $=1 if example $x^{(i)}$ is in cluster j or 0 otehrwsie\n",
    "\n",
    "### k-means ++\n",
    "* improve the clustering resulst through more clever seeding of the initial cluster cetners\n",
    "* classic k-means use random seedin\n",
    "1. initialzie an empty set M, to store the k centroids being selected\n",
    "2. randomly chosoe the first centroid $\\mu^{(j)} $ from the input exampels and assing it to M\n",
    "3. for each example that is not in M, find the minimum squared distance $d(x^{(i)},M)^2$ to any of the centroids in M\n",
    "4. to randomly select the next centroid $\\mu^{(p)}$ use a weighted probability distributon $\\frac {d(\\mu^{(p)},M)^2} {\\sum_i d(x^{(i)},M)^2}$\n",
    "5. repeat 2 and 3 until k centorids are chosen\n",
    "6. proceed with classic k-means\n",
    "\n",
    "## Hard and soft clustering\n",
    "* Hard clustering: family of algorithms where each example in a dataset is assinged to exactly one cluster\n",
    "* Soft clustering / fuzzy clustering : assign an example to one or more clusters\n",
    "    * a popular example is fuzzy C-means (FCM), also called soft k-means or fuzzy k-means\n",
    "    \n",
    "## Fuzzy C-means\n",
    "* replace hard cluster assignment with probabilities for each point belonging to each cluster\n",
    "1. specify the number of k centroids and randomly assign the cluster memberships for each point\n",
    "2. computer the cluster centroids $\\mu^{(j)} , j \\in (1,...,k)$\n",
    "3. update the cluster memberships for each point\n",
    "4. repeat steps 2 and 3 until the membership coefficients do not change or a user-defined tolerance or maximum number of iterations is reached\n",
    "* $ J_m = \\sum_{i=1}^n \\sum_{j=1}^k w^{(i,j)m} ||x^{(i)} -\\mu^{(j)}||_2^2$\n",
    "    * m- any number greater than or equal to one (typically m=2) is the fuzziness coefficient / fuzzifier, control the degree of fuzziness, larger m, smaller the cluster membership becomes, fuzzier clusters\n",
    "    * $w^{(i,j)} = [\\sum_{c=1}^k (\\frac{||x^i - \\mu^i||_2}{||x^i - \\mu^c||_2})^{\\frac{2}{m-1}}]^{-1} $\n",
    "    \n",
    "## Elbow method to find optimal number of clusters\n",
    "* to quantify the quality of clustering, need to use intrinsic metrics, such as the within-cluster SSE (distortion) to compare the performance of different k-means clusterings\n",
    "* based on the within-cluster SSE, we can use elbow method to estimate the optimal number of clusters, k, for a given task\n",
    "* the elbow is the optimal choice for number of clusters\n",
    "* as k increases, distortion decreases\n",
    "\n",
    "## Silhouette plots\n",
    "* silhouette analysis - a plot to measure how tightly grouped the examples in the clsuters are\n",
    "* to calculate the silhouette coefficient of a single exampel:\n",
    "1. calculate the cluster cohesion $a^{(i)}$ as the average distance between an example, $x^{(i)}$ and all other points in the same cluster, tells how similar it is to other examples in its own clusters\n",
    "2. calculate the cluster separation $b^{(i)}$ from the next closest cluster as the average distacne between the example $x^{(i)}$ and all exampels in the nearest cluster - quantifies how dissimilar an example is from other clusters\n",
    "3. calculate the silhouette $s^{(i)}$ as the difference between cluster cohesion and separation divided by the greater of the two\n",
    "* $s^{(i)} = \\frac {b^{(i)} -a^{(i)}} {max(b^{(i)},a^{(i)})}$\n",
    "    * bounded in range -1 to 1\n",
    "    * 0 if cluster separation and cohesion are equal $b^{(i)} =a^{(i)}$\n",
    "    * ideal is 1\n",
    "* can easily tell clusters that contain outliers\n",
    "\n",
    "## Hierarchical clustering\n",
    "* allows us to plot dendrograms (visualizaitons of a binary hierarchical clustering)\n",
    "* two main approaches:\n",
    "    * agglomerative - start with each example as an individual cluster and merge the closest pairs of clusters until only one cluster remains\n",
    "    * divisive - start with one cluster that encompasses the complete dataset, iteratively split the cluster into smallers clusters until each cluster only contains one example\n",
    "\n",
    "### Agglomerative hierarchical clustering\n",
    "* two std algorithms:\n",
    "    * single linkage - compute the distance between the most similar members for each pair of clusters and merge the two clusters for which the distance between the most similar members is smallest\n",
    "    * complete linkage - compare the most dissimilar members to perfrom the merge\n",
    "* others:\n",
    "    * average linkage - merge based on min average distances between all group members in the two clusters\n",
    "    * Ward's linkage - the two clsuters that lead to the minimum increase of the total within-cluster SSE are merged\n",
    "* let's use the complete linkage:\n",
    "1. computer the distance matrix of all examples\n",
    "2. represent each data point as a singleton cluster\n",
    "3. merge the two cloesest based on distance between the most dissimilar (distant) members\n",
    "4. update the similarity matrix\n",
    "5. repeat 2-4 until one single cluster remains\n",
    "\n",
    "## DBSCAN\n",
    "* Density-based spatial clustering of applicaitons with noise (DBSCAN)\n",
    "* assing labels based on dense regions of points\n",
    "* density is defined as the number of points within a specific radius $\\epsilon$\n",
    "* the following criteria are used to assing example:\n",
    "    * a point is considered core point if at least a MinPts number of neighboring points fall within the specified radisu $\\epsilon$\n",
    "    * a border point is a point that has fewer neighbors than MinPts within $\\epsilon$ but lies within $\\epsilon$ radius of a core pint\n",
    "    * all other points are noise points\n",
    "* steps:\n",
    "1. form a separate cluster for each core point or connected gropu of core points\n",
    "2. assign each border point to the cluster of its correspodning core point\n",
    "* disadvantage is that with an increasing number of features in our dataset, the negative effect of the curse of dimensionality increases - finding a good combo of MinPts and $\\epsilon$ difficult if density differences in the datasets are relatively large\n",
    "\n",
    "## Graph-based clustering\n",
    "* most prominent are the spectral clustering algorithms\n",
    "* use the eigenvectors of a similarity or distance matrix to derive their cluster relaitonships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 12 : Implementing a Multilayer Artifical Neural Network from Scratch\n",
    "\n",
    "## MLP\n",
    "* units in the hidden layer are fully connected to the input layer and the output layer is fully connected to the hidden layer\n",
    "* if such a network has more than 1 hidden layer, then it is a deep artificial NN\n",
    "* the error gradients become increasingly small as more layers are added - vanishing gradient\n",
    "* special algorithms developed to train such DNN structure, known as deep learning\n",
    "\n",
    "## forward propagation\n",
    "1. startin at the input layer, forward propagate the patterns of training data through the network to generate an output\n",
    "2. based on the network's output, calculate the error that we want to minimize using a cost function\n",
    "3. backpropagate the error, find its derivative with respect to each weight in the network, update the model\n",
    "* then calculate network output and apply threshold function to obtain the predcited class labels\n",
    "* MLP is a typical example of a feedforward aritficial NN\n",
    "    * feedforward refers to each layer serves as the input to the next layer wihtout loops\n",
    "\n",
    "## MNIST handwritten digits\n",
    "* NumPy's savez function - save multidimensional arrays to disk, creates zipped archives of our data, producing .npz files that contains files in .npy files\n",
    "* savez_compressed would compresses the output file down to way smaller file size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 13 & Chapter 14 : TensorFlow\n",
    "* TensorFlow is a scalable and multiplatform programming interface for implementing and running machine learning algorithms\n",
    "* allows execution on both CPUs and GPUs\n",
    "* built around a computation graph composed of a set of nodes, each node an operation that may have zero or more input or output\n",
    "* tensor is created as a symbolic handle to refer to the input and output of these operations\n",
    "* computation graph : a network of nodes, with each node resembling an opeartion, which appleis a function to its input tensor and returns zero or more tensors as the output\n",
    "* supports automatic differentiation, implementation of the chain rule for computing gradients of nested functions\n",
    "\n",
    "## TensorFlow Keras API\n",
    "* Keras is a high-level NN API\n",
    "* originally developed to run on top of other libraries such as TensorFlow and Theano\n",
    "\n",
    "## Machine learning with pre-made Estimators\n",
    "1. Define an inpupt function for data loadin\n",
    "2. convert the dataset into feature columsn\n",
    "3. instantiate an Estimator or use a pre-made Estimator\n",
    "4. use Estimator methods : train() , evaluate() , and predict()\n",
    "\n",
    "## Creating a custom Estimator from an existing Keras model\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 15 : Deep Convolutional Neural Networks\n",
    "\n",
    "## Convolutional neural networks (CNNs)\n",
    "* for image classification\n",
    "* inspired by visual cortex\n",
    "* successfully extracting silent relevant features is the key to the performance\n",
    "* CNN are able to automatically learn the features form raw data\n",
    "    * the early layers extract low-level features from raw data\n",
    "    * the later layers (often fully connected layers) use these features to predict a continuous target value or class label\n",
    "* construct 'feature hierarchy' by combining low-level features in a layer-wise fashion to form high-level features\n",
    "* CNN computres feature maps from an input image\n",
    "    * each element comes from a local patch of pixels in the input image, the local receptive field\n",
    "* CNN does well on image because:\n",
    "    * sparse connectivity - a single element in the feature map is connected to only a small patch of pixels\n",
    "    * paramter-sharing - the same weights are used for different patches of the input image\n",
    "* subsampling layers / pooling layers do not have any learnable paramters\n",
    "* both convulutional and fully connected layers have weights and biases\n",
    "\n",
    "## Discrete convolution / convolution\n",
    "* discrete convolultion for two vectors x and w is denoted by $ y=x*w$\n",
    "    * x is the input/ signal , w is the filter or kernel\n",
    "    * y = x * w -> $ y[i] = \\sum_{k=-\\infty}^{+\\infty} x[i-k] w[k]$\n",
    "    * padding with zeros - zero padding\n",
    "* there is:\n",
    "    * full padding - output larger than the input size\n",
    "    * valid padding - padding so that the output vector has the same size as the input\n",
    "    * same padding - preserves the size of the original vector, no padding\n",
    "* size of output reulsitng from y = x * w with padding p, stride s: $ o= floor [ \\frac {n+2p-m} {s} ]+1$\n",
    "\n",
    "## Subsampling layers\n",
    "* two forms of pooling opeartions in CNNs:\n",
    "    * max-pooling - takes the max from the neighborhood\n",
    "    * mean-pooling / average-pooling - takes the average of the neighborhood\n",
    "* the pooling layer denoted by $P_{n1 x n2}$\n",
    "    * the subscript determines the size of the neighborhood - pooling size\n",
    "\n",
    "## Regularizing an NN with dropout\n",
    "* don't know how large the network should be a priori\n",
    "* build a network with a relatively large capacity to do well on training, then apply regularization to acheive a good generationzation performance on new data\n",
    "* dropout is a regularization method\n",
    "    * usually applied to the hidden units of higher layers\n",
    "    * during training phase of NN, a fraction of the hidden units is randomly dropped at every iteration with probability $\\rho_{drop}$ commonly set to 0.5\n",
    "    * the weights associated with the remaining neurons are rescaled to account for the dropped neurons\n",
    "    * force network to learn a redundant representation of data and cannot reply on an activation of any set heavily\n",
    "* inverse dropout\n",
    "    * inconvenient to scale the activations to account for dropout when making predicitons, TensorFlow scale the activations during training by doubling activation if $\\rho_{drop} =0.5$\n",
    "    \n",
    "## Loss functions\n",
    "* activation functions\n",
    "    * ReLU mainly used in the hidden layer of an NN to add non-linearities\n",
    "    * sigmoid and softmax at the output layer to get class-membership probabilities as the output\n",
    "* so for classificaiton, we also need to choose different loss function for different problem and output\n",
    "    * binary cross-entropy - loss function for a binary classificaiton\n",
    "    * categorical cross-entropy - loss function for multiclass classificaiton\n",
    "    * can get logits or probabilities as output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 16: Recurrent Neural Networks\n",
    "\n",
    "## Sequential data / sequences\n",
    "* typical machine learning algorithms for supervised learning assume the input is independent and identically distributed (IID) data\n",
    "    * training examples are mutually independent and have the same underlying distribution\n",
    "* but for sequences, order matters\n",
    "* predicting market value of a stock would be an example\n",
    "    * time-series\n",
    "* word\n",
    "    * text data, DNA sequences\n",
    "    * language\n",
    "* music\n",
    "\n",
    "## Representing sequences\n",
    "* $<x^{(1)}, x^{(2)}, ... , x^{(T)}>$\n",
    "* RNNs are designed for modeling sequences and are capable of remembering past info and processing new events accordingly\n",
    "\n",
    "## Relationship categories of input and output\n",
    "* many-to-one\n",
    "    * input is a sequence but output is a fixed-size vector or scalar\n",
    "    * sentiment analysis\n",
    "* one-to-many\n",
    "    * input is standard format but output is sequence\n",
    "    * image captioning\n",
    "* many-to-many\n",
    "    * both input and output are sequences\n",
    "    * can be synchoronized\n",
    "        * video classificaiton where each frame in a video is labeled\n",
    "    * delayed\n",
    "        * translating one language to another- must read entire English sentence first before translating to German\n",
    "\n",
    "## RNN\n",
    "* the hidden layer receives its input from both the input layer of its current time step and the hidden layer from the previous time step\n",
    "* have a memory of past events\n",
    "* this flow of info displayed as a loop, recurrent edge, in graph notation\n",
    "* so hidden layers would have sequences as input then sequences as output until the output layer, which might have sequence or normal standard format as output\n",
    "* BPTT- backpropogation through time:\n",
    "    * overall L is the sum of all loss functions at times t=1 to t=T\n",
    "    * $L = \\sum_{t=1}^T L^{(t)}$\n",
    "* output recurrence:\n",
    "    * net activations from the output layer at the previous time step can be added in one of two ways:\n",
    "        * to the hidden layer at the current time step $h^t$\n",
    "        * to the output layer at the current time step $o^t$\n",
    "        * basically can have hidden-to-hidden, output-to-hidden, or output-to-output recurrence\n",
    "* BPTT backpropagation has new challenges, becuase the multiplicative factor dht/dhk, vanishing and exploding gradient problems arise. At least 3 solutions:\n",
    "    * graident clipping - specify a cut-off / threshold\n",
    "    * TBPTT - limits the number of time steps that the signal can be backpropagated after each forward pass\n",
    "    * LSTM  - long short-term memory cells\n",
    "\n",
    "## Long short-term memory cells (LSTMs)\n",
    "* building block is a memory cell, reprsenets / replaces the hidden layer of standard RNNs\n",
    "* each memory cell has a recurrent edge that has the desirable weight, w =1\n",
    "* values associated with this recurrent edge collectively called the cell state\n",
    "* three different types of gates:\n",
    "    * forget gate - reset the cell state without growing indefinitely, decide what info go through and which to suppress\n",
    "        * $ f_t = \\sigma(W_{xf}x^{(t)} + W_{hf}h^{(t-1)} +b_f)$\n",
    "    * input gate and candidate value update the cell state:\n",
    "        * $i_t = \\sigma(W_{xi}x^{(t)} + W_{hi}h^{(t-1)} +b_i)$\n",
    "        * $\\tilde{c}_t= tanh(W_{xc}x^{(t)} + W_{hc}h^{(t-1)} +b_c)$\n",
    "        * cell state at time c : $C^{(t)} = (C^{(t-1)} * f_t) + (i_t * \\tilde{c}_t)$\n",
    "    * output gate decides how to update the values of hidden units:\n",
    "        * $o_t = \\sigma(W_{xo}x^{(t)} + W_{ho}h^{(t-1)} +b_o)$\n",
    "        * hidden unit at current time step: $h^{(t)} = o_t * tanh(C^{(t)})$\n",
    "* alternative - GRU : a recurrent layer with a gated recurrent unit\n",
    "\n",
    "## Transformer architecture\n",
    "* can model global dependencies between input and output sequences\n",
    "* self-attention mechanism - our model would be able to learn to focus on the parts of an input sequence that are more relevant to the sentiment in a sentiment analysis\n",
    "\n",
    "### self-attention\n",
    "* have an input sequence of length T and an output sequence\n",
    "    * both are with size d\n",
    "    * basically a seq2seq task\n",
    "* want to model the dependcies of each element in the output to the input elemetns, to do so, three stages:\n",
    "    1. derive importance weights based on the similiarity between curretn and all other elements in the sequence (get the dot product)\n",
    "        * for input element $x^{(i)}$ and each jth element in range [0,T], computer dot product $x^{(i)}x^{(j)}$\n",
    "    2. normalize the weights (softmax)\n",
    "        * $W_ij$ = softmax($x^{(i)}x^{(j)}$)\n",
    "    3. use these weights in combo with correspodning sequence elements to compute the attention value (weighted sum over the entire input sequence)\n",
    "        * $ o^{(i)} = \\sum_{j=0}^T W_{ij} x^{(j)}$\n",
    "    * output is the weighted sum of all input sequences\n",
    "* if we want to learn a language model and want to change the attention values to optimize an object, need to change the word embeddings (input vectors) that underlie each input element\n",
    "* need to introduce 3 additional weight matrices to update and change attention values: $U_q , U_k, U_v$\n",
    "    * query seq: $q^{(i)} = U_q x^{(i)} for i \\in [0,T]$\n",
    "        * $q^{(i)}$ size $d_k$ = m\n",
    "        * $U_q x^{(i)}$ size m x d\n",
    "    * key  $k^{(i)} = U_k x^{(i)} for i \\in [0,T]$\n",
    "        * $k^{(i)}$  size $d_k$ = m\n",
    "        * $U_k x^{(i)}$ size m x d\n",
    "    * value  $v^{(i)} = U_v x^{(i)} for i \\in [0,T]$\n",
    "        * $U_v x^{(i)}$ size $d_v$ x d\n",
    "    * $w_{ij} = q^{(i)T} k^{(j)}$\n",
    "        * to normalize: $W_{ij} = softmax(\\frac{w_{ij}}{\\sqrt{m}})$\n",
    "        \n",
    "### multi-head attention (MHA)\n",
    "* combines multiple self-attention operations together\n",
    "* each self-attention mechanism is called a head, which can be computed in parallel\n",
    "* using r parallel heads, each head results in a vector, h, of size m\n",
    "* these vectors are then concatenated to obtain a vector, z, with the shape r x m\n",
    "* concatenated vector is proejcted using the output matri $W^o$ to obtain the final output : $o^{(i)} = W_{ij}^o z$\n",
    "\n",
    "### Transformer architecture\n",
    "* Transfomre block has the input sequence, MHA, layer norm, MLP (fully connected), then the output sequence\n",
    "    * residual connection - adds the output from a layer to its input, x + layer(x)\n",
    "        * block consisting of a layer with sucha residual connection is called a residual block\n",
    "    * layer normalizaiton (layer norm) is a family of normalization layers including batch normalziaiton\n",
    "        * to normalize or scale the NN inputs and activations in each layer\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 17: GANs\n",
    "\n",
    "* synthesize new data samples\n",
    "\n",
    "## Autoencoders\n",
    "* can compress and decompress training data\n",
    "* composed of two networks concatenated togetehr: an encoder network and a decoder network\n",
    "    * encoder network receives a d-dimensional input feature vector associated with example x and encodes it into a p-dimensional vector z\n",
    "        * learn how to model the function z = f(x)\n",
    "    * decoder acts as a data compression function: decompresses $\\hat{x}$ from the lower-dimensional latent vector z\n",
    "        * $\\hat{x}$ = g(z)\n",
    "        \n",
    "## Generative adversarial networks (GANs)\n",
    "* generative model can generate new example $\\hat{x}$ from a random vector z\n",
    "* random vector z comes from a simple distribution with fully known characteristics so we can sample from such a distribution\n",
    "* similar to decoder component of an autoencoder\n",
    "    * both receive latent vector z as input and return an output in the same space as x\n",
    "    * difference is we don't know the distribution of z in autoencoder but we know it for a generative version\n",
    "    * can generalize an autoencoder into a generative modle- VAEs\n",
    "\n",
    "### VAEs\n",
    "* receive input example x, encoder network is modified in such a way that it computes two moments of the distribution of the latent vector : mean $\\mu$ and variance $\\sigma^2$\n",
    "* during training, network is forced to match these moments with those of a standard normal distribution\n",
    "* after training, encoder is discarded and use the decoder network to generate new example $\\tilde{x}$ by feeding random z vectors from the learned Gaussian distribution\n",
    "\n",
    "### the loss functions of the geneartor and discriminator networks\n",
    "* $V(\\theta^{(D)} , \\theta^{(G)}) = E_{x~\\rho data(x)} [logD(x)] + E_{z~pz(z)}[log(1- D(G(z)))]$\n",
    "    *  $V(\\theta^{(D)}$ the value function, a payoff:\n",
    "        * want to maximize its value with resepct to the discriminator D while minimizing its value with respect to generator G\n",
    "    * D(x) is the probability that indicates whether the input example x is real or fake\n",
    "    * expression $E_{x~\\rho data(x)} [logD(x)]$: expected value of the quantity in brackets with resepct to the examples from data distribtuion (the real examples)\n",
    "    * $E_{z~pz(z)}[log(1- D(G(z)))]$ expected value of quantity with respect to the distribution of the input z vectors\n",
    "1. maximzie payoff for discriminator\n",
    "2. minimize payoff fro generator\n",
    "* alternating between the two, fix the paramters of one network and optimzie the weights of the other one\n",
    "* but log(1-D(G(z))) faces the vanishing gradients problem - to solve it\n",
    "    * instead of minimizing $E_{z~pz(z)}[log(1- D(G(z)))]$, replace it with maximizing $E_{z~pz(z)}[log(D(G(z)))]$\n",
    "    * means swap real and fake exmamples and carry out a regular function minimizaiton\n",
    "    * would mean minimzing binary cross-entropy loss\n",
    "    \n",
    "## Transposed convolution\n",
    "* also called fractionally strided convolution\n",
    "* also soemtiemes called deconvolution\n",
    "* focused on recovering the original dimensionality of the feature space and NOT the actual values\n",
    "* used to upsample the feature space\n",
    "* works by inserting 0s between the elements of input feature maps\n",
    "\n",
    "## Batch normalization\n",
    "* BatchNorm - normalziing the layer inputs and preventing changes in their distribution during trainging, enables faster and better convergence\n",
    "* transforms a mini-batch of features based on its computed statistics\n",
    "1. compute the mean and std dev of the net inputs for each mini-batch\n",
    "    * mean : $\\mu_B = \\frac {1}{m *h*w} \\sum_{i,j,k} Z^{[i,j,k,.]}$\n",
    "    * std dev: $\\sigma_B^2 = \\frac {1}{m *h*w} \\sum_{i,j,k} (Z^{[i,j,k,.]}-\\mu_B)^2$\n",
    "    * both have size c\n",
    "2. standardize the net inputs for al lexampels in the batch:\n",
    "    * $z_{std}^{[i]} = \\frac {Z^{[i]} - \\mu_B} {\\sigma_B + \\epsilon}$\n",
    "3. scale and shift the normalized yet inputs using two learnable paramter vectors $\\gamma$ and $\\beta$ of size c:\n",
    "    * $A_{pre}^{[i]} = \\gamma Z_{std}^{[i]} + \\beta$\n",
    "* make the net inputs mean-centered and have unit variance\n",
    "* initially developed to reduce internal covairance shift-  the changes that occur in the distribution of a layers actions due to updated network paramters - epoch 1 and epoch 2 might have different layer activations\n",
    "* but research shown that the effect on fixing internal covariance shift is minimal, but isntead BatchNorm is able to smooth out the loss function\n",
    "\n",
    "## Dissimilarity measures between two distributions\n",
    "* total variation (TV)\n",
    "    * measure the largest difference between the two distributions at each point\n",
    "    * the function supremum, sup (S) refers to the smallest value that is greater than all elements of S- the least upper bound for S\n",
    "* Kullback-Leibler (KL) divergence\n",
    "    * not symmetric\n",
    "    * measrues the relative entropy of the distribution P with resepct to referene distirbution Q\n",
    "* Jensen-Shannon (JS) divergence\n",
    "    * symmetric\n",
    "    * GANs loss function minimizes the JS divergence between the distribution of real and fake examples\n",
    "* Earth mover's (EM) distance\n",
    "    * infimum function inf(S), refers to the largest value that is smaller than all elemetns of S ( the greatest lower bound)\n",
    "    * minimal amount of work needed to transform one distribution into the other\n",
    "    * proposed to replace JS divergence in use in GAN because\n",
    "        * for a line at x=0 and the other at x= $\\theta$, where $\\theta >0$, the EM distance EM(P,Q) = |$\\theta|$, whose gradient with resepct to $\\theta$ exists and can push Q toward P\n",
    "        \n",
    "## Gradient penalty (GP)\n",
    "* instead of clipping the weights for trainign a GAN model, can have gradient penalty\n",
    "1. for each pair of real and fake examples in a given batch, choose a random number from a uniform distribution\n",
    "2. calcualte the interpolation between the real and fake examples\n",
    "3. computer the discriminator (critic) output for all interpolated examples\n",
    "4. calcualte the gradietns of the critic's output with resepct to each interpolated example\n",
    "5. computer gradient penalty, total loss then equal $L_{total}^D = L_{real}^D + L_{fake}^D + \\lambda L_{gp}^D$ with $\\lambda$ as a tunable hyperparamter\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter 18 : Reinforcement Learning (RL)\n",
    "* focused on learning a series of actions for optimzing an overall reward\n",
    "* learning from experience\n",
    "* different from supervised or unsupervised learning\n",
    "* goal is to learn the underlying structure of a dataset\n",
    "* learning by interaction by maximizing a reward function\n",
    "* the model is also called the agent, interacts with its enviornment and by doing so generates a sequecne of interactions called episode.\n",
    "* reward can be positive and negative\n",
    "* the sequence - dependence in RL creates a delayed effect - the action taken at time step t may result in future reward some arbitrary number of steps later, makes traiing difficult\n",
    "* all RL have two dinstinct entities:\n",
    "    * agent\n",
    "    * environment\n",
    "* reward signal si the feedback that agent receives from interacting with the environment\n",
    "* learning process:\n",
    "    * agent try different actions (exploration) so it can progressively learn which actions to prefer and perform more often (exploitation) to maximize the total cumulative reward\n",
    "        * usually exploration can potentially result in greater total rewards in the long run while exploration has greater short-term reward\n",
    "\n",
    "## Theoretical foundations\n",
    "* Markov decision processes (MDPs)\n",
    "    * standard approach is by using dynamic programming but RL have several advantages over it\n",
    "    * MDPs are the types of problems that require learning an interactive and sequential decision-making process, where the deciison at time step t affects the subsequent situations\n",
    "* dentoe agent's starting staet as $S_0$, then the intearciton between agent and envionrment would be {$S_0,A_0,R_1$} ...\n",
    "    * $S_t$ and $R_{t+1}$ have probabilyt distributions that only depend on their value at the preceding time step t-1\n",
    "    * the probability distribtuion compeltely defines th dynamics of the environemtn because based on this distribtuion, all transiton prob of the environment can be computed\n",
    "    * the types of RL methods that requires a model of the environmetn or try to learn a model of the envirnometn are called model- bassed\n",
    "    * enivornment dynamics deterministic if particular actions for given states are ALWAYS or NEVER taken, otherwise, have stochastic beahvior\n",
    "        * prob of observing the future state $S_{t+1} - s'$ conditioned on the curretn staet $S_t = s$ and the performed action $A_t = a$, then the state-transition probability:\n",
    "            * $p(s'|s,a) = \\sum_{r \\in \\hat{R} } p(s',r|s,a)$\n",
    "            \n",
    "\n",
    "## Model-free and Model-based\n",
    "* model-free\n",
    "    * Monto Carlo (MC)\n",
    "    * temporal difference (TD)\n",
    "\n",
    "## Episodic versus continuing tasks\n",
    "* as the agent interacts with the environment, the sequence of observations or states forms a trajectory\n",
    "* there are two types of trajectories:\n",
    "    * if an agent's trajectory can be divided into subparts such that each starts at time t = 0 and ends in a terminal state $S_T$ (at t = T) - episodic task\n",
    "        * playing chess\n",
    "        * an episode is a sequence or trajectory that an agent takes from a starting state\n",
    "    * if trajectory is infinitely continuous without a terminal state - continuing task\n",
    "        * keeping a house tidy\n",
    "\n",
    "## RL terminology\n",
    "* the return - return at time t is the cumulated reward obtaiend from the entire duration of an episode\n",
    "    * $R_{t+1} = r$ is the immediate reward after performing an action $A_t$ at time t\n",
    "* return at time t can be calculated from the immediate reward as well as the subsequent ones: $G_t = R_{t+1} + \\gamma R_{t+2} + \\gamma^2 R_{t+3} + ... = \\sum_{k=0} \\gamma^k R_{t+k+1}$\n",
    "    * $\\gamma$ is the discount factor in ragne [0,1], indicates how much the future rewards are \"worth\" at the current moment (time t)\n",
    "    * by setting $\\gamma = 0$, we would imply that we do not care about the future rewards, return will be equal to the immediate reward. ignoring the subsequent rewards after t+1 and the agent will be short-sighted\n",
    "    * if $\\gamma = 1$, return will be the unweighted sum of all subsequent rewards\n",
    "    * equation for the return can be expressed in a simpler way using a recursion: $G_t = R_{t+1} + \\gamma G_{t+1} = r + \\gamma G_{t+1}$\n",
    "* policy - denoted by \\pi(a|s) is a function that determines the next action to take, which can be either determinisitc, or stochastic\n",
    "    * stochastic policy has a prob distribution over actions that an agent can take at a given state : $\\pi (a|s) = P[A_t = a | S_t = s]$\n",
    "    * policy might change as the agent gains more experience\n",
    "    * optimal is the policy that yields the highest return\n",
    "* value function / state-value function - measures the goodness of each state - how good or bad it is to be in a particular state\n",
    "    * usually estimate the value function using lookup tables so we do not have to recomputer it multiple times\n",
    "    * we can define a value for each state-action pair (action-value function) and is denoted by $q_{\\pi}(s,a)$\n",
    "    * action-value function refers to the expected return $G_t$ when the agent is at state $S_t = s$ and take action $A_t = a$\n",
    "* reward is consequence of the agent taking an action, states with high or good value are those with high expected return\n",
    "    * eg. computer only receives a reward for winnign the game, it does not get an immediate reward by making this move that captures the opponents's queen, but the new state may have a high value, which may or may not yield a reward\n",
    "    * return is the weighted sum of rewards for an entire epsidose, value function is the expectation over all possible episodes\n",
    "\n",
    "## Dynamic programming using Bellman equation\n",
    "* one of the central elements of many RL algorithms\n",
    "* simplifies the computation of the value function\n",
    "* relates the value function for a state , s, to the value function of its subsequent staet s'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
